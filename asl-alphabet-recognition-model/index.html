<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>ASL Alphabet Recognition Model - rswilson32.github.io</title><meta name="description" content="The Project This model classifies images of the American Sign Language (ASL) alphabet. According to the National Institute of Health, over 860,000 North Americans use ASL either as a primary or secondary language as of 2006, and we hope that our model can contribute to making communication more accessible for&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://rswilson32.github.io/asl-alphabet-recognition-model/"><link rel="alternate" type="application/atom+xml" href="https://rswilson32.github.io/feed.xml"><link rel="alternate" type="application/json" href="https://rswilson32.github.io/feed.json"><meta property="og:title" content="ASL Alphabet Recognition Model"><meta property="og:image" content="https://rswilson32.github.io/media/posts/12/american_sign_language-2.PNG"><meta property="og:site_name" content="rswilson32.github.io"><meta property="og:description" content="The Project This model classifies images of the American Sign Language (ASL) alphabet. According to the National Institute of Health, over 860,000 North Americans use ASL either as a primary or secondary language as of 2006, and we hope that our model can contribute to making communication more accessible for&hellip;"><meta property="og:url" content="https://rswilson32.github.io/asl-alphabet-recognition-model/"><meta property="og:type" content="article"><link rel="stylesheet" href="https://rswilson32.github.io/assets/css/style.css?v=e9f4a19ad1e985cd2261c22304c8c641"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://rswilson32.github.io/asl-alphabet-recognition-model/"},"headline":"ASL Alphabet Recognition Model","datePublished":"2023-12-20T14:38","dateModified":"2023-12-28T18:01","image":{"@type":"ImageObject","url":"https://rswilson32.github.io/media/posts/12/american_sign_language-2.PNG","height":489,"width":876},"description":"The Project This model classifies images of the American Sign Language (ASL) alphabet. According to the National Institute of Health, over 860,000 North Americans use ASL either as a primary or secondary language as of 2006, and we hope that our model can contribute to making communication more accessible for&hellip;","author":{"@type":"Person","name":"Roger","url":"https://rswilson32.github.io/authors/roger/"},"publisher":{"@type":"Organization","name":"Roger"}}</script></head><body><div class="container"><header class="header"><a href="https://rswilson32.github.io/" class="logo">rswilson32.github.io</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu">Menu</button><ul class="navbar__menu"><li><a href="https://github.com/rswilson32" target="_blank">github</a></li><li><a href="https://www.linkedin.com/in/rswilson32/" target="_blank">linkedIn</a></li></ul></nav><div class="search"><div class="search__overlay js-search-overlay"></div><button class="search__btn js-search-btn" aria-label="Search"><svg role="presentation" focusable="false" height="16" width="16"><use xlink:href="https://rswilson32.github.io/assets/svg/svg-map.svg#search"/></svg></button></div></header><main class="main"><article class="post"><header class="post__inner post__header"><h1 class="post__title">ASL Alphabet Recognition Model</h1><div class="post__meta"><div class="post__meta__left"><a href="https://rswilson32.github.io/authors/roger/" class="invert post__author" rel="author" title="Roger">Roger</a></div><div class="post__meta__right"><time datetime="2023-12-20T14:38" class="post__date">December 20, 2023</time><div class="post__updated">Updated on <time datetime="2023-12-20T14:38" class="post__date">December 28, 2023</time></div></div></div></header><figure class="post__featured-image"><div class="post__featured-image__inner"><img src="https://rswilson32.github.io/media/posts/12/american_sign_language-2.PNG" srcset="https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-2-xs.PNG 384w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-2-sm.PNG 600w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-2-md.PNG 768w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-2-lg.PNG 1200w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-2-xl.PNG 1600w" sizes="(min-width: 37.5em) 1600px, 80vw" loading="eager" height="489" width="876" alt=""></div></figure><div class="post__inner"><div class="post__entry"><div class="container-lg px-3 my-5 markdown-body"><h3 id="the-project">The Project<a class="anchorjs-link" href="https://rswilson32.github.io/ASL-MNIST-recognition-model/#the-project" aria-label="Anchor" data-anchorjs-icon=""></a></h3><p>This model classifies images of the American Sign Language (ASL) alphabet. According to the National Institute of Health, over 860,000 North Americans use ASL either as a primary or secondary language as of 2006, and we hope that our model can contribute to making communication more accessible for individuals who sign. This was my final project for my machine learning class at UCLA. While it was a group project, we worked on creating three separate convolutional neural networks (CNN) to compare different architectures and their performances on our data. The following code and opencv program were my contributions. Since we were developing an image recognition model, convolutional neural networks were the natural choice as they are flexible, and we need a model that is invariant under translation of the input. We believe that using convolutional neural networks will maximize our overall image recognition accuracy.</p><h3 id="the-data">Data<a class="anchorjs-link" href="https://rswilson32.github.io/ASL-MNIST-recognition-model/#the-data" aria-label="Anchor" data-anchorjs-icon=""></a></h3><p>The training and testing data is from the Sign Language MNIST data, which contains 27,455 training images and 7,712 testing images. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because they involve motions). Each 28x28 pixel image is represented as a vector with grayscale values between 0-255. The original hand gesture image data represented multiple users repeating the gesture against different backgrounds. To create new data, “an image pipeline was used based on ImageMagick and included cropping to hands-only, gray-scaling, resizing, and then creating at least 50+ variations to enlarge the quantity”.</p><figure class="post__image post__image--center"><img loading="lazy" src="https://rswilson32.github.io/media/posts/12/american_sign_language.PNG" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-xs.PNG 384w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-sm.PNG 600w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-md.PNG 768w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-lg.PNG 1200w, https://rswilson32.github.io/media/posts/12/responsive/american_sign_language-xl.PNG 1600w" alt="" width="876" height="489"></figure><h3 id="model">Model<a class="anchorjs-link" href="https://rswilson32.github.io/ASL-MNIST-recognition-model/#model" aria-label="Anchor" data-anchorjs-icon=""></a></h3><p>The model is built in PyTorch with four convolution layers and a fully connected layer at the end. I also employed max pooling to down-sample our feature maps. At the end of our pipeline, the network includes two fully connected layers followed by batch normalization and dropout. I used dropout in the fully connected layer instead of in the convolutions. The first convolutional layer processes a single input channel, gradually increasing the number of channels in the next layers. ReLU activation functions are applied throughout the network. A dropout rate of 0.2 is also applied at the end. Through hyperparameter tuning, this CNN achieved 98.2% accuracy with a batch size of 64, Adam optimizer, a learning rate of 0.001, and 8 epochs.</p><h3 id="camera-application">Camera Application<a class="anchorjs-link" href="https://rswilson32.github.io/ASL-MNIST-recognition-model/#camera-application" aria-label="Anchor" data-anchorjs-icon=""></a></h3><p>We also implemented a real-time ASL alphabet camera recognition system using the opencv library designed for computer vision and my trained model’s weights. The program recognizes images in a given region of interest (ROI) which we designate with a green square. The frame is then captured, set to gray-scale, and blurred. We are then able to classify the hand gesture using our previously trained CNN.</p><h3>Code</h3><p>The code can be found on <a href="https://github.com/rswilson32/ASL-MNIST-recognition-model" target="_blank" rel="noopener noreferrer">this GitHub repository</a>. To run the camera application, download <a href="https://github.com/rswilson32/ASL-MNIST-recognition-model/blob/main/camera_recognition.py" target="_blank" rel="noopener noreferrer">camera_application.py</a>, which has the CNN, classifying function and camera function, and <a href="https://github.com/rswilson32/ASL-MNIST-recognition-model/blob/main/cnn156.pt" target="_blank" rel="noopener noreferrer">cnn156.pt</a>, the PyTorch parameters for the CNN. simply running 'python camera_application.py' in your console will start the camera.</p></div><figure class="post__image post__image--center"><img loading="lazy" src="https://rswilson32.github.io/media/posts/12/aslmath.PNG" sizes="(min-width: 37.5em) 1600px, 80vw" srcset="https://rswilson32.github.io/media/posts/12/responsive/aslmath-xs.PNG 384w, https://rswilson32.github.io/media/posts/12/responsive/aslmath-sm.PNG 600w, https://rswilson32.github.io/media/posts/12/responsive/aslmath-md.PNG 768w, https://rswilson32.github.io/media/posts/12/responsive/aslmath-lg.PNG 1200w, https://rswilson32.github.io/media/posts/12/responsive/aslmath-xl.PNG 1600w" alt="" width="843" height="246"></figure></div><footer class="post__footer"><div class="post__tag-share"><div class="post__share"></div></div></footer></div></article><div class="post__related"><h3 class="post__related__title">Related posts</h3><div class="l-grid l-grid--2"><article class="c-card"><div class="c-card__wrapper"><figure class="c-card__image"><img src="https://rswilson32.github.io/media/posts/14/Sar.png" srcset="https://rswilson32.github.io/media/posts/14/responsive/Sar-xs.png 384w, https://rswilson32.github.io/media/posts/14/responsive/Sar-sm.png 600w, https://rswilson32.github.io/media/posts/14/responsive/Sar-md.png 768w, https://rswilson32.github.io/media/posts/14/responsive/Sar-lg.png 1200w" sizes="(min-width: 37.5em) 80vw, 50vw" loading="lazy" height="571" width="1024" alt=""></figure><div class="c-card__content"><header><h2 class="c-card__title"><a href="https://rswilson32.github.io/santa-maria-de-sar-model/" class="invert">Santa Maria de Sar Model</a></h2></header><footer class="c-card__meta"></footer></div></div></article><article class="c-card"><div class="c-card__wrapper"><figure class="c-card__image"><img src="https://rswilson32.github.io/media/posts/9/biking.webp" srcset="https://rswilson32.github.io/media/posts/9/responsive/biking-xs.webp 384w, https://rswilson32.github.io/media/posts/9/responsive/biking-sm.webp 600w, https://rswilson32.github.io/media/posts/9/responsive/biking-md.webp 768w, https://rswilson32.github.io/media/posts/9/responsive/biking-lg.webp 1200w" sizes="(min-width: 37.5em) 80vw, 50vw" loading="lazy" height="213" width="380" alt=""></figure><div class="c-card__content"><header><h2 class="c-card__title"><a href="https://rswilson32.github.io/california-commuting-patterns-2/" class="invert">Bike Rental Model</a></h2></header><footer class="c-card__meta"></footer></div></div></article></div></div></main><footer class="footer"><div class="footer__left"><div class="footer__copy">Powered by Publii</div></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://rswilson32.github.io/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = { mobileMenuMode: 'sidebar', animationSpeed: 300, submenuWidth: 'auto', doubleClickTime: 500, mobileMenuExpandableSubmenus: true, relatedContainerForOverlayMenuSelector: '.navbar', };</script><script defer="defer" src="https://rswilson32.github.io/assets/js/scripts.min.js?v=8190bbfcf662a6d5bf1ad35d88ad1ec9"></script><script>function publiiDetectLoadedImages () {
         var images = document.querySelectorAll('img[loading]:not(.is-loaded)');
         for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
               images[i].classList.add('is-loaded');
               images[i].parentNode.classList.remove('is-img-loading');
            } else {
               images[i].addEventListener('load', function () {
                  this.classList.add('is-loaded');
                  this.parentNode.classList.remove('is-img-loading');
               }, false);
            }
         }
      }
      publiiDetectLoadedImages();</script></body></html>